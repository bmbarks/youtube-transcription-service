name: youtube-transcription-service

# NOTE: Using Dockerfile-based build (not buildpacks)
# This enables faster-whisper + Python + Node.js in one container

services:
  - name: app
    # Docker-based deployment
    dockerfile_path: Dockerfile
    github:
      branch: main
      repo: barkstech/youtube-transcription-service
    http_port: 3000
    health_check:
      http_path: /health
      initial_delay_seconds: 60
      period_seconds: 30
      timeout_seconds: 10
      success_threshold: 1
      failure_threshold: 3
    instance_count: 1
    # Upgraded: basic-xs (512MB) can't run Whisper
    # professional-xs: 1 vCPU, 2GB RAM (~$12/mo) - minimum for transcription
    instance_size_slug: professional-xs
    envs:
      - key: NODE_ENV
        value: production
      - key: PORT
        value: "3000"
      - key: REDIS_URL
        scope: RUN_AND_BUILD_TIME
        type: SECRET
      - key: DO_SPACES_KEY
        scope: RUN_AND_BUILD_TIME
        type: SECRET
      - key: DO_SPACES_SECRET
        scope: RUN_AND_BUILD_TIME
        type: SECRET
      - key: DO_SPACES_REGION
        value: nyc3
      - key: DO_SPACES_BUCKET
        value: barkstech-media
      - key: DO_SPACES_ENDPOINT
        value: https://nyc3.digitaloceanspaces.com
      - key: API_KEY_SECRET
        scope: RUN_AND_BUILD_TIME
        type: SECRET
      - key: WHISPER_MODEL
        value: small
      - key: WHISPER_DEVICE
        value: cpu
      - key: WORKER_CONCURRENCY
        value: "1"
      - key: LOG_LEVEL
        value: info
      - key: ENABLE_YOUTUBE_TIER
        value: "true"
      - key: ENABLE_WHISPER_TIER
        value: "true"
      - key: ENABLE_FALLBACK
        value: "true"
    log_destinations:
      - name: app-logs

databases:
  - name: redis-db
    version: "7"
    engine: REDIS
    production: true
